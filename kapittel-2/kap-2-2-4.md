# Bearbeiding og klargjøring av tekst korpus for analyse

Verken Norsk aviskorpus eller Atekst er tilgjengelig gjennom en såkalt API.[^API] Hadde det vært det, kunne jeg hentet ut datamaterialet direkte i den strukturen og formen som var mest hensiktmessig for dette prosjektet. I stedet for var jeg avhengig av å bruke de forskjellige eksport-mulighetene som var tilgjengelig gjennom nettsidene. Norsk aviskorpus lar deg laste ned de fleste tabeller i et såkalt tabulator-separert-format, som lett lar seg omgjøre og importere som regneark eller tabeller.

Atekst gir også en rekke eksporteringsmuligheter, blant annet som rentekst med visse muligheter. Atekst kan for eksempel markere søkeord i artiklene med understrek (for eksempel «dette er \_spiritualitet\_ i praksis») som kan gjøre det enklere å jobbe med materialet fordi dette er en typografisk anomali og lett å søke etter. Siden jeg brukte en bolsk søkestreng hvor de eksporterte filene inneholder mange forskjellige trefford, kunne jeg med regulære utrykk søke etter `_\w+_` (understrek+alle ord-karakterer med en til uendelig mange bokstaver+understrek) for å få alle treffene.

Eksportfilene fra Atekst er bygget opp slik

-	Metainformasjon om søket
-	Indeks over søketreff med tittel, avisnavn og dato
-	De enkelte artiklerene med følgende struktur:
	-	Tittel
	-	------------------------------------------------------------------------------
	-	Avis, dato
	-	Skribentnavn\*
	-	Sidetall\*
	-	Trykkformat (f.eks «Trykket på papir»)
	-
	-	Ingress\*
	-
	-	 Brødtekst
	-
	-	 Bildetekst\*
	-	 URL til pdf-versjon\*
		 ==============================================================================

\*Kun dersom dette er i artikkelen.

Atekst følger ikke avsnittsmarkeringer som ligger i avisene, men lager nye linjer omtrent rundt 80+/- tegn. Dette er ikke optimalt dersom man ønsker å gjøre korpuslingvistiske analyser ved hjelp av programmeringspråk. En linje i et slikt dokument representerer nemlig noe spesielt dersom man er avhengig av å bruke regulære utrykk eller en del av metodene som ligger i programmeringspråk som Python. Det er derfor en fordel å få all brødtekst på én linje. Det er også ønskelig å hente ut metadata til artiklene og lagre alt på sin rette plass i egne kolonner i en database.

For å gjøre dette var jeg nødt til å først finne en måte å lese og gjøre om de eksporterte filene fra Atekst. Etter en del prøving og feiling med forsjellige metoder (for eksempel bruk av regulære utrykk i tekstbehandlingsprogrammet [BBedit](http://www.barebones.com/products/bbedit/)), fant jeg til slutt ut at den beste måten å gå frem på var å bruke programmeringspråket Python. I tillegg til å være rimelig enkelt, spesielt om man kjenner til programmering fra før, har Python en del moduler som er nyttige i forbindelse med prosjekter innenfor det digitale humaniora.[^xkcd] Selv om jeg så og si aldri hadde brukt Python før, klarte jeg etter et par uker med testing, prøving og feiling, å lage et skript som gikk igjennom en slik eksportfil fra Atekst, delte den opp og satt den sammen i det formatet jeg ønsket. Dette skriptet har jeg publisert på [GitHub](https://github.com/kmelve/atekst-txt-to-csv) hvor det også blir forbedret.

Uten å gå inn i tekniske detaljer (se da kommentarer i selve skriptet) så gjør skriptet følgende: Først skiller den ut indeksdelen fra filen. Deretter går den igjennom linjene og deler filen opp i en ny bit når den finner 78 «er lik»-tegn (=) etter hverandre. Så går den igjennom alle disse delene og skiller ut overskrift, dato, avis, annen informasjon og brødtekst. Den fjerner også alle linjeskift i prøvdteksten slik at hele artikkelen kommer på én linje. Så setter den i sammen filen igjen, og legger dessuten inn komma mellom de ulike verdiene. For å hindre at komma, anførsels- og andre spesialtegn blir tolket feil av andre programmer som skal gå igjennom disse filene, så passer den på markere disse med et «escape«-tegn som i dette tilfellet er bakover-skråstrek.

[^xkcd]: [Som illustrert i webtegneserien xkcd](http://xkcd.com/353/)
[^API]: Application Programming Interface.

